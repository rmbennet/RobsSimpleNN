{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary packages:\n",
    "import numpy as np\n",
    "from NN import layers\n",
    "\n",
    "#Import the data:\n",
    "#stored separately and imported here\n",
    "# as a matrix of X and a *column vector* for the y's\n",
    "from data.data import X_train, y_train\n",
    "\n",
    "\n",
    "#Wait for this stuff: not ready:\n",
    "from NN.loss_function import BCE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the `learning_rate`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.03"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the `Linear` layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_layer = layers.Linear(num_features=X_train.shape[1], num_neurons=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Input data `X_train` to linear layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.26933483, 0.73066517],\n",
       "       [0.26933483, 0.73066517],\n",
       "       [0.26933483, 0.73066517],\n",
       "       [0.26933483, 0.73066517]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = linear_layer.forward(X_train)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\"predictions\"\n",
    "#assumed to be meaningless at first pass:\n",
    "np.argmax(output,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#actuals\n",
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Compute the Binary Cross Entropy Loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8127999637059493"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = BCE(y_true=y_train , y_pred = output)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Compute Gradients\n",
    "\n",
    " - The derivations of these gradients is completed in the readme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_output = output - y_train\n",
    "dz = d_output * (output) * (1-output)\n",
    "d_weights = np.dot(X_train.T, dz)\n",
    "d_bias = np.mean(dz , axis= 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Update the weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_layer.weights -= lr*d_weights\n",
    "linear_layer.bias -= lr*d_bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Repeat Steps 1 through 4 a large number of times.  Take note of how the loss function progresses and what happens to prediction accuracy after training is complete:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.26933483,  0.73066517],\n",
       "       [-1.73066517, -1.26933483],\n",
       "       [-1.73066517, -1.26933483],\n",
       "       [ 0.26933483,  0.73066517]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_output - y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.8128\n",
      "Epoch 10000, Loss: 0.8128\n",
      "Epoch 20000, Loss: 0.8128\n",
      "Epoch 30000, Loss: 0.8128\n",
      "Epoch 40000, Loss: 0.8128\n",
      "Epoch 50000, Loss: 0.8128\n",
      "Epoch 60000, Loss: 0.8128\n",
      "Epoch 70000, Loss: 0.8128\n",
      "Epoch 80000, Loss: 0.8128\n",
      "Epoch 90000, Loss: 0.8128\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100000):\n",
    "    #STEP 1:\n",
    "    output = linear_layer.forward(X_train)\n",
    "    \n",
    "    #STEP 2:\n",
    "    loss = BCE(y_true=y_train , y_pred = output)\n",
    "    \n",
    "    #STEP 3:\n",
    "    d_output = output - y_train\n",
    "    d_weights = np.dot(X_train.T, dz)\n",
    "    d_bias = np.mean(dz , axis= 0)\n",
    "    \n",
    "    #STEP 4:\n",
    "\n",
    "    linear_layer.weights -= lr*d_weights\n",
    "    linear_layer.bias -= lr*d_bias\n",
    "\n",
    "    #Give periodic updates on the loss function:\n",
    "    if epoch % 10000 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n",
    "        #weights gradient apppears to be getting stuck\n",
    "        #print(f'd_weights at epoch {epoch}: {d_weights}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.73066517, 0.26933483],\n",
       "       [0.73066517, 0.26933483],\n",
       "       [0.73066517, 0.26933483],\n",
       "       [0.73066517, 0.26933483]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not ideal.  The network has learned $\\begin{bmatrix}0.5 & 0.5\\\\0.5 & 0.5\\\\0.5 & 0.5\\\\0.5 & 0.5\\end{bmatrix}$ when the actual outputs are $\\begin{bmatrix}0\\\\1\\\\1\\\\0\\end{bmatrix}$.  This may be due to choice of loss function, or not enough layers/neurons."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
